{"/":{"title":"üìù Daniel's Notes.","content":"\n\n","lastmodified":"2023-03-03T12:41:54.196982198Z","tags":null},"/private/Projects/Large/AI-opera":{"title":"AI opera","content":"---\n\nI've been going to the opera recently, and it is really great. As i sit there in the dark I think about the type of opera I'd make, and it involves a story told in time jumps between the future and the recent past of AI, and quite possibly about conciousness.\nFor one act or set piece I imagine it has a giant screen arrangement suspended from the ceiling, a bit like the [[private/Transmediale notes#Unconscionable Maps|the works of Evan Roth]] and a lonley hacker \"plugged in\" through a funnel of cables.\nThematically (and musically) realted to [Deus Ex](https://en.wikipedia.org/wiki/Deus_Ex_(video_game)), as one part is set in post hydro-wars carbon-wars of the near future.\nOther locations inlcude a slum near a pumping station in south east asia like [Lower Bicutan](https://goo.gl/maps/kHa1FhNfRT3f2d3u5)\nI need to watch more contemporary operas, and find whatever happened to that lady that worked at the royal opera house whom I met at Sussex.\n\nChoreographed forearm performance can be used to convey inductive computing. See: [Choreographed, limb-centric performance / Sadeck Waff](https://youtu.be/ekibVX3gK5Q)\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Large/Creative-AI-report":{"title":"Creative AI report","content":"---\n\nSee [[private/Projects/Things I think we should do#Projects]] for more:\n\n![[private/Projects/Things I think we should do#Projects]]\n\nThis would need external funding, perhaps from a smaller start to scope it, e.g.\n\n¬£1.5-2k to scope it --\u003e departamental grant\n¬£10k to do a first edition --\u003e Turing/TAS money\n\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Large/Promptology":{"title":"Promptology","content":"---\n\nA coffee table book about vernacular AI art as it developed before/besides [DALLE2](https://openai.com/dall-e-2/) and subsequent corporate takeover.\n\nThe idea is to have several large super striking images and their prompts printed in large format and high quality, accompanied by essays on text-2-image systems. I've been thinking about whether these prompts might be gotten from a specific group of people, or with a specific theme, but I now think a broader theme like possible futures might be better.\nAnd also possibly something we can get from  [[private/Projects/Things I think we should do| a \"prompetition\" organised by CAIL]]  \nWe ask people to send us their prompts and we select, render, and upscale them using CREATE. We offer some form of prize.\nI also thought about workshoping these images between artists and essay writers.","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Large/Synthetic-Media-and-Generative-Approaches-in-the-Humanities":{"title":"Synthetic Media and Generative Approaches in the Humanities","content":"---\n\nLarger project. Work on bid for this  üí∞\n\nReference for this event and ask Aurora about recordings:\n\n![Responses from media studies towards a \"new paradigm\" of image production](https://pbs.twimg.com/media/Fm7WJcUXgAA5V9F?format=jpg\u0026name=4096x4096)\n\n![[assets/FpqZ7QIXgAQdSuD.jpeg]] This image was created using #controlnet and #stablediffusion ","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Large/VANGE":{"title":"VANGE","content":"---\n\nVideo Analysis Generative Engine\n\nAn idea for a tool to make computational video essays. There is a diagram for this in my office.\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Small/Computational-video-essay":{"title":"Computational video essay","content":"---\n\nUpdate the dataset: mine the [Movieclips YT channel](https://www.youtube.com/@MOVIECLIPS) again\nTake control over the database?\nAnnotate the dataset with object detection.\nRefactor code to have a front end, downloading the YT videos on the fly.\nPublish the dataset and add a data paper.\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Projects/Things-I-think-we-should-do":{"title":"CAIL: Things I think we should do","content":"---\n\nGive substance to some of the weaker claims of the position paper.\n\n## Education\nSince we (at KCL) are actually a large teaching operation, and CAIL now has critical mass of permanent members of staff, we should consider specific training/education initiatives that fit our activities. Possible options:\n- Creative AI module ‚Äï level 6, practice-based, in the flex curriculum, using [e-research](https://docs.er.kcl.ac.uk/CREATE/access/)/NMEs teaching support. Possibly with invited lecturers each week? Could this be interesting to artists (Serpentine)?\n- Summer workshop ‚Äï once a year, sprint-like, theme-based, artists (Serpentine), academics, students, and engineers.\n- Student curating ‚Äï students find and curate AI Art advised by CAIL\n- Creative AI competition\n\n## Projects\n- Book sprint with Meson Press? ‚ÄïMercedes\n- [[private/Projects/Large/Creative AI report|Creative AI report]] Survey of the field leveraging research expertise form colleagues in the department, and Serpentine could broker access to the artists for interviews, etc. Maybe can be updated every year? ref. [Oxford report](https://www.oii.ox.ac.uk/news-events/reports/ai-the-arts/). \u003c--are we not much better positioned to do this type of thing?\n\n## Research outputs\n(sorry for the corporate temrinology)\n\n- JVC edited volume\n- Events\n\t- CAIL co-sponsored [[Transmediale 2023|Toward a Minor Tech]]\n\t- CAIL position paper Launch event\n\t- Book launch / conversation ‚ÄïJussi's new book, others?","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Teaching/7AAVDM52":{"title":"7AAVDM52","content":"---\n\n- [ ] Share this example of [successful Hollywood movies](https://informationisbeautiful.net/visualizations/what-is-the-most-successful-hollywood-movie-of-all-time/#interactive) for my visualisation students.\n- [ ] Update KEATS with weekly readings\n- [ ] Upload visualisation types cheat sheet and article.\n\n\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Teaching/7AAVDM57":{"title":"7AAVDM57","content":"---\n\nIdeas for students projects:\n\nUse scenarios/diagrams form the Scientific Trieste's [[private/Transmediale notes#Unconscionable Maps|Scientific Dreaming]] project.\n\nUse delivery workers a one of the target groups for students.\n\n\n\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/Teaching/Marking":{"title":"Marking","content":"---\n\n- [x] Second mark 6AAVC403 Digital Gaming deadline 28 February\n- [ ] First marking User-Centered Research 7AAVDM58 8 March\n- [x] Second mark 5AAVC209 Design in the Digital World ASAP!\n\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/Books":{"title":"Books to buy","content":"---\n\n- [ ] Simon St√•lenhag (use in my prompts for the cover of [[private/To do/Cinema and Machine Vision]])\n\t- The Electric State\n\t- Tales from the Loop\n\t- Things from the Flood\n\n\n- [ ] [Aesthetic Computing](https://mitpress.mit.edu/9780262562379/aesthetic-computing/) by Paul A. Fishwick\n- [ ] [Photography and the optical unconscious](https://www.dukeupress.edu/photography-and-the-optical-unconscious) Shawn Michelle Smith, Sharon Sliwinski\n- [ ] [The Feel of Algorithms](https://www.ucpress.edu/book/9780520394551/the-feel-of-algorithms) by Minna Ruckenstein","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/Cinema-and-Machine-Vision":{"title":"Cinema and Machine Vision","content":"---\n\nFinish this book!","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/Human-centered-machine-vision":{"title":"Human'centered machine vision?","content":"\n---\n\n\n\nUpload the slides fro this event, and a note about the event with the recording, pictures, etc.","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/Reading-List":{"title":"Reading List","content":"---\n\n- [ ] [Field-level differences in paper and author characteristics across all fields of science in Web of Science, 2000‚Äì2020](https://doi.org/10.1162/qss_a_00246)\nI want to know from this how digital humanities fare compared to traditional arts and humanities\n\n\u003eAbstract\n\nWith increasing availability of near-complete, structured bibliographical data, the past decade has seen a rise in large-scale bibliometric studies attempting to find universal truths about the scientific communication system. However, in the search for universality, fundamental differences in knowledge production modes and the consequences for bibliometric assessment are sometimes overlooked. This article provides an overview of article and author characteristics at the level of the OECD minor and major fields of science classifications. The analysis relies on data from the full Web of Science in the period 2000‚Äì2020. The characteristics include document type, median reference age, reference list length, database coverage, article length, co-authorship, author sequence ordering, author gender, seniority, and productivity. The article reports a descriptive overview of these characteristics combined with a principal component analysis of the variance across fields. The results show that some clusters of fields allow inter-field comparisons, and assumptions about the importance of author sequence ordering, while other fields do not. The analysis shows that major OECD groups do not reflect bibliometrically relevant field differences, and that a reclustering offers a better grouping.\n\n\n\n- [ ] [Deepfakes and the Epistemic Apocalypse](https://philpapers.org/archive/HABDAT-2.pdf)\n\n\u003eAbstract:\n\u003eIt is widely thought that deepfake videos are a significant and unprecedented threat to\nour epistemic practices. In some writing about deepfakes, manipulated videos appear as the\nharbingers of an unprecedented\nepistemic apocalypse. In this paper I want to take a critical\nlook at some of the more catastrophic predictions about deepfake videos. I will argue for\nthree claims: 1) that once we recognise the role of social norms in the epistemology of\nrecordings, deepfakes are much less concerning, 2) that the history of photographic\nmanipulation reveals some important precedents for deepfakes which correct claims about\nthe novelty of deepfakes, and 3) that proposed solutions to deepfakes have been overly\nfocused on technological interventions. My overall goal is not so much to argue that\ndeepfakes are not a problem, but to argue that behind concerns around deepfakes lie a\nmore general class of social problems about the organisation of our social practices.\n\n- [ ] [Deceitful Media](https://global.oup.com/academic/product/deceitful-media-9780190080365?cc=nl\u0026lang=en\u0026) by Simone Natale","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/To-buy":{"title":"To buy","content":"---\n\n- [ ] Coat hanger\n- [x] Floor divider\n- [x] Bin bags\n- [x] Milk\n- [x] Hula Hops for lunch\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/To-do-weekend":{"title":"To do weekend","content":"---\n\n- [ ] Closet door / finish closet\n- [ ] Storage wars en buhardilla\n- [x] Weather station batteries\n- [ ] Install batteries\n- [ ] Credit card\n- [x] Pay hot water Wandsworth\n- [x] Buy Kurious tickets\n- [ ] Meal plan\n- [ ] Buy peak district train tickets","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/private/To-do/Towards-a-Computational-Video-Essay":{"title":"Towards a Computational Video Essay","content":"---\n\nLatest revisions:\n\n- [x] Discuss the main line of argumentation more explicitly at the beginning of the article (to make the contributions more visible).\n- [x] Make an effort to establish a better dialogue with the digital humanities/cultural analytics (e.g. via Arnold and Tilton's work) in the theoretical framework.\n- [x] In practice these two steps mostly involve bringing up a few sentences/aspects here and there.\n- [x] Divide preliminary results (perhaps call initial insights and reflection) and conclusion.\n\n\n\n\nReviewer(s)' Comments to Author:  \n  \nReviewer: 1  \n  \nComments to the Author  \nI can see that the manuscript has been revised, especially in the introduction. To me, it is still necessary to engage more extensively and more clearly with the literature to support the paper's claim of relevance and originality. The theoretical framework in the revised manuscript is not very elaborate, and the author also acknowledges it is as such (‚Äúnot to be understood as a fully-fledged theoretical framework‚Äù and ‚ÄúSave for notable exceptions [‚Ä¶] it would be fair to say‚Ä¶‚Äù). It is necessary to position your own research more clearly within the field.  \n\nPlease look into the following:  \n- [x] include a more substantial literature review on the fields to which you contribute. It is necessary to elaborate on the ideas of the main authors of each field as it enables to clarify your own contribution  \n\n~~not sure if elaborating on the main authors mentioned, but can write something about distant viewing, explain how it applies the principles of distant reading to moving images, and how it is concerned with finding patterns in large collections of cultural artefacts. \nMy contribution aims to make visible the sampling operation and data modelling involved in creating the conditions for these distance, namely, how distant viewing spatialises time-based media. \nThe practice I propose re-inscribes these patterns found through computational analysis in time, returning the critic to familiar mode of analysis by giving data objects duration\nIs not so much distant viewing, but rather condensed viewing; a computationally-enabled form of probing moving images in time, through the familiar strategies of montage and the syntactic and synoptic apparatus of (dis)continuity as a meaning-making modality that operates through sequential rather than spatial proximity. \nThus not plotting moving images as data points in space, but making these data points flow in a timeline. Using the critic's ability to think through time, and to give these proximities a narrative content.~~\n\n~~up close by sampling~~\n\n- [x] be more clear and more specific about your own contribution to all the fields, especially to the field of video essays and to the field of digital humanities  \n- [x] integrate a clearer dialogue between existing scholarship/findings and own method in the sections where you introduce and evaluate your method  \n  \nOther comments:  \n- [x] The conclusion is for me the strongest part of the article. Therefore, I would love to see more of the conclusion in the main text, and in the introduction (in which you can announce the main argument of the paper more explicitly)  \n- [x] The author introduces new results and figures in the conclusion. I suggest to move these results and figures to the results' section.  \n- [x] Minor detail: In the conclusion, it becomes clear that the author did not finish the research on/for the method yet ('preliminary'). This frames the paper a bit as a work-in-progress paper which is not finished yet. Re-phrase it e.g. by stating that the first part of the (evaluation of the) method is finished and presented in this article, and that there will be follow-up research in another paper. Also remove the 'preliminary' from the conclusion's title.  \n  \n  \nReviewer: 2  \n  \nComments to the Author  \nI do think the author has sufficiently improved the article and I recommend publishing it. I only have minor remarks to the response and discussion of cultural analytics in the article (also in light of the other reviewer's comments), notably that the author considers their work only \"tangentially related\" to cultural analytics. I am not entirely convinced by this (also because the discussion of cultural analytics remains cursory in the article and indeed does leave out Arnold and Tilton's work which certainly does reflect a more complex approach/definition of Cultural Analytics than the one offered in the article - yet again, I do think the article can be published as is in spite of this).\n\n\n\n~~More testing and development are needed to fully gauge the limits and possibilities of this way of producing computational supercuts.~~\n\n~~I expect there will be more supercuts available in the same online repository at the time of publication~~\n\n~~The supercut is a palimpsest in structure ‚Äïan artefact of artefacts‚Äï and, as Tohline argues, a material instantiation of algorithmic thinking. In its computational form, I submit it can also be thought of as an audiovisual programming interface: a way of performing data-science through images, in which the techniques of film editing are used to interrogate machine learning operations such as data sampling, feature extraction, and error optimisation. If through the mass datafication of culture the film archive became a database, through machine learning this database is now a computational model. The question before us now is not only how to analyse moving images using computational methods, but more broadly, how to interrogate, call to account, and intervene, the computational modelling of visual culture at large. In other words, how to live with and among models that simultaneously reduce and expand what can be seen and known at specific historical junctures.~~\n\n\nFrom ChatGpt:\n\nexplain cultural analytics, quantitative film analysis, and computational humanities, including distant viewing, for a literature review in a research paper\n\n\u003eCultural Analytics, Quantitative Film Analysis, and Computational Humanities are interdisciplinary fields that use computational tools and methods to analyze and study cultural expressions and artifacts such as literature, film, and visual arts. They aim to understand the patterns, trends, and relationships among different cultural expressions and to provide insights into the cultural and historical context in which they were produced.\n\n\n~~\u003eQuantitative Film Analysis is a subfield of Cultural Analytics that focuses on the use of computational methods to analyze film data. This includes the analysis of visual and audio features of films, such as shot length, color palette, and sound design, as well as the analysis of textual data, such as scripts and reviews. Quantitative Film Analysis is used to study film style, genre, and representation, and to provide insights into the historical and cultural context in which films were produced.~~\n\n\u003eComputational Humanities is an interdisciplinary field that uses computational tools and methods to study the humanities. This includes the use of computational techniques to analyze literary texts, visual arts, music, and film. Computational Humanities seeks to provide new ways of understanding cultural expressions and artifacts and to shed light on the cultural and historical context in which they were produced.\n\n\u003eDistant viewing is a method in computational humanities that uses computational techniques to analyze large collections of cultural data without close examination of individual items. The goal of distant viewing is to identify patterns, trends, and relationships at a large scale and to provide a quantitative understanding of cultural expressions. This method allows for the analysis of vast amounts of cultural data in a systematic and objective manner, providing new insights into the cultural and historical context of cultural expressions.\n\n\u003eIn conclusion, Cultural Analytics, Quantitative Film Analysis, and Computational Humanities are interdisciplinary fields that use computational tools and methods to study cultural expressions and artifacts. They provide new ways of understanding cultural phenomena and provide insights into the cultural and historical context in which they were produced. The use of distant viewing in computational humanities is a valuable method for analyzing large collections of cultural data and provides a quantitative understanding of cultural expressions at scale.\n\n~~Videographic criticism and the video essay are emerging scholarly practices in media studies that use the medium of video to analyze, interpret, and critique media artifacts, such as films, television shows, and video games. These practices represent a new form of media analysis that combines traditional critical methods, such as close reading and textual analysis, with audiovisual elements, such as editing, sound design, and animation.\n\n~~Catherine Grant, Christian Keathley, and Jason Mittell are leading scholars in the field of videographic criticism and the video essay. Catherine Grant is known for her work on the theory and practice of videographic film and moving image studies. In her work, she explores the potential of videographic criticism to enrich our understanding of film and moving images through the use of audiovisual elements.\n\n~~Christian Keathley is a film scholar who has made significant contributions to the development of videographic criticism as a scholarly practice. He is particularly interested in the relationship between the moving image and the viewer, and how videographic criticism can provide new ways of understanding the experience of watching films.\n\n~~Jason Mittell is a media scholar who has made important contributions to the field of videographic criticism and the video essay. In his work, he explores the use of video as a tool for critical analysis and the ways in which video can be used to tell stories and make arguments about media artifacts. Mittell is also interested in the potential of the video essay to foster a new form of public scholarship that combines the academic rigor of traditional scholarship with the accessibility and engagement of digital media.\n\n~~In conclusion, videographic criticism and the video essay are emerging scholarly practices in media studies that use the medium of video to analyze and critique media artifacts. These practices represent a new form of media analysis that combines traditional critical methods with audiovisual elements. Scholars such as Catherine Grant, Christian Keathley, and Jason Mittell have made significant contributions to the development of these practices and have explored their potential to enrich our understanding of media artifacts and foster a new form of public scholarship.~~\n\n~~But with the system in place, I expect to render more supercuts and make them available in the same online repository by the time of publication. I also plan two follow-up pieces of research to further explore the epistemic and aesthetic potential of the computational video essay.~~\n\nResponse:\n\nTo both reviewers:\nThank you for your comments and valuable feedback.\nI revised the text accordingly, and found especially useful your comments about clarifying the contribution in relation to cultural analytics. This prompted a more thorough revision than I had initially anticipated, made me go back to recover additional sources I had left in out in the initial draft, and helped me adjust the title of the piece to better reflect my own position.\nI also included two new figures to illustrate the main arguments in the text, and a filmography in the references section.\nI believe the balance between theoretical and processual writing is better and the piece clearer as a result. Please find my response on the specific points you raised below, and a revised version of the article attached.\n\nIn response to reviewer 1\n\n- I have elaborated on the theoretical framework, expanding on the ideas of the main authors I engage with, and re-framing the review of literature to better clarify my own contribution in relation to cultural analytics, which I also hope is now more evident with the adjusted title of the piece.\n- To address the structural points raised about the last part of the text, I reorganised the \"preliminary results\" and \"conclusions\" sections into  \"findings and evaluation\" and a \"future research\". This clarifies for the reader what research was already carried out, the findings of it, and future work in the field, I think.\n- I moved several points from the conclusions to the introduction, as suggested, to better signpost the overall contribution of the piece.\n\nIn response to reviewer 2\n\n- I engage more with cultural analytics, I also make a more explicit reference to Arnold and Tilton's \"distant viewing\" work, in both the literature review and the findings and evaluations section.\n- I also made explicit the relation my approach has with existing  cultural analytics methods and practices, including a clearer distinction of epistemic modalities and how these are linked through inductive computing.\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/public_notes/Creative-AI-Theory-and-Practice":{"title":"Creative AI Theory and Practice","content":"---\n\n [Twitter thread about this from King's AI institute](https://twitter.com/aiatkings/status/1628419338200809472?s=20) \n\nThe [recording](https://youtu.be/xuZsf3ZX7k8) of this event is online.","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/public_notes/Digital-Theory-Lab-NYU-Prague":{"title":"NYU - Prague","content":"---\n\n# Cultural Metabolism and LLMs on wheels\n\n## Abstract\nLarge Language Models ( #LLMs ) trained on vast ammounts of internet text are able to simulate natural language structures to a degree that enables novel interfaces for human-computer interaction. One key function in these systems can be observed at the micro level, when the next token in an unfolding series is predicted and concatenated recursively, in other words, at the logical step when calculation becomes synthesis.\nIn this presentation I focus on this very localised but crucial moment of exchange, drawing a parallel with metabolic processess in cellular biology, to explore the notion of self-contained and embeded autonomous systems: LLMs+ or LLMs on wheels.\n\n[[moving_pixel/quartz/content/public_notes/Creanalytics | creanalytics]]\n\n","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/public_notes/Human-centered-machine-vision":{"title":"Human-centered machine vision?","content":"---\n\nFrom the _Click and Collect: Show Me Your Dataset_ event at Somerset House. See the  [twitter thread](https://twitter.com/sh_studios_/status/1626900453828005889?s=20). I presented ongoing research on the [[private/To do/Towards a Computational Video Essay | Computational Supercut]], forthcoming as an article in a special issue on _Critical Technical Practice_ in the journal [Convergence](https://journals.sagepub.com/home/con).\nI'll post the full recording here if/when it's available.\n\n![[assets/FpPpVlVWIAE1uFq.jpeg]]","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/public_notes/The-Digital-Pastoral":{"title":"The Digital Pastoral","content":"---\n\nI created the image below using #stablediffusion for my very short presentation at [[Transmediale 2023 | Transmediale 2023]].\n\n\n![[assets/minor_tech_DCH.jpg]]\n\n\nAnd here's [a link to the newspaper](https://darc.au.dk/fileadmin/DARC/newspapers/toward-a-minor-tech-online-sm.pdf)!","lastmodified":"2023-03-03T12:41:54.200982428Z","tags":null},"/public_notes/Tools/Mermaid-diagrams":{"title":"Mermaid diagrams","content":"\n\u003eJavaScript based diagramming and charting tool that renders Markdown-inspired text definitions to create and modify diagrams dynamically.\n\nIt has a [live editor](https://mermaid.live/) for non-programmers, and has [some tutorials](https://mermaid.js.org/config/Tutorials.html). Maybe relevant for students. There's a Jupyter integration too. Interesting for #criticaltechnicalpractice \nMaybe I can use this to render an maintain a web version of the [[private/Projects/Large/VANGE]] diagram in my office.\n\n![Mermaid](https://mermaid.js.org/header.png)\n\n","lastmodified":"2023-03-03T12:41:54.204982658Z","tags":null},"/public_notes/Tools/Motion-Canvas":{"title":"Motion Canvas","content":"---\n\n\u003eVisualize Complex Ideas Programmatically.\n\u003eIt's a specialized tool designed to create informative vector animations and synchronize them with voice-overs. It's not meant to be a replacement for traditional video editing software.\n\nProcedural animation tool, that can be integrated with a web-editor to sync sound and produce animated videos. Great for education, documentation, and reflection in #criticaltechnicalpractice Reminds me a bit of Flash action script, but #FOSS and nicer for rapid development and to comunicate abstract ideas precisely. Think of [Freya Holm√©r](https://www.youtube.com/@Acegikmo) videos or [Ms Coffee Beans](https://www.youtube.com/@AICoffeeBreak).\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/H5GETOP7ivs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n","lastmodified":"2023-03-03T12:41:54.204982658Z","tags":null},"/public_notes/Transmediale-2023":{"title":"Transmediale 2023","content":"---\n\nI attended [Transmediale](https://2023.transmediale.de/en) and gave a very small presentation as part of the panel *Toward Minor Tech*.\n\n[![Towards a Minor Tech Newspaper](assets/images/minor_tech_news.jpeg)](https://darc.au.dk/fileadmin/DARC/newspapers/toward-a-minor-tech-online-sm.pdf)\n\nThis is the result of a workshop organised by by Geoff Cox and Christian Ulrik Andersen every year as part of [SHAPE Digital Citizenship](https://shape.au.dk/en/) \u0026 [Digital Aesthetics Research Center, Aarhus University](https://darc.au.dk/) and [Centre for the Study of the Networked Image, London South Bank University](https://www.centreforthestudyof.net/), this year in collaboration with [King‚Äôs College London](https://www.kcl.ac.uk/). \n\nThe workshop took place over several days in London and inlcuded public talks from Marloes de Valk on the [damaged earth catalog](https://damaged.bleu255.com/) and from Tung-Hui Hu on [digital lethargy](https://thephotographersgallery.org.uk/whats-on/talk-digital-lethargy).\nMy contribution to the publication was titled: *A minor critique of minor tech* and can be found as a PDF, along with all other contirbutions, by clicking [here](https://darc.au.dk/fileadmin/DARC/newspapers/toward-a-minor-tech-online-sm.pdf).\n\n![minor tech panel](assets/images/minor_tech_panel.jpeg)\n","lastmodified":"2023-03-03T12:41:54.204982658Z","tags":null}}