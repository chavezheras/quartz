<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine vision on</title><link>https://garden.movingpixel.net/tags/machine-vision/</link><description>Recent content in machine vision on</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Tue, 23 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://garden.movingpixel.net/tags/machine-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>Video as data in the US</title><link>https://garden.movingpixel.net/public_notes/Video-as-data/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Video-as-data/</guid><description>This looks interesting! See twitter post here.
![[assets/images/Pasted image 20230523190034.png]]</description></item><item><title>Streaming Video Model</title><link>https://garden.movingpixel.net/public_notes/Tools/Streaming-Video-Model/</link><pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Streaming-Video-Model/</guid><description>Interesting video model that accounts for frames and sequences in a unified model. Abstract:
Video understanding tasks have traditionally been modeled by two separate architectures, specially tailored for two distinct tasks.</description></item><item><title>Human-centered machine vision?</title><link>https://garden.movingpixel.net/public_notes/Human-centered-machine-vision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Human-centered-machine-vision/</guid><description>From the Click and Collect: Show Me Your Dataset event at Somerset House. I was invited as part of a panel with Charlotte Webb and Kristina Pulejkova to discuss human-centred design in relation to AI.</description></item></channel></rss>