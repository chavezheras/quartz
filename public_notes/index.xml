<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Public_notes on</title><link>https://garden.movingpixel.net/public_notes/</link><description>Recent content in Public_notes on</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 17 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://garden.movingpixel.net/public_notes/index.xml" rel="self" type="application/rss+xml"/><item><title>cinematic time</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/cinematic-time/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/cinematic-time/</guid><description>This strand on table 3 focused on cinematic time at the most local level: from shot to shot and even frame to frame; a kind of computational poetics of moving images, which is probably the closest to my own work.</description></item><item><title>day two</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/day-two/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/day-two/</guid><description>7 July Fast prototyping session On day two, we gathered again to decide what ideas we could put to the test and fast-prototype.</description></item><item><title>historical time</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/historical-time/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/historical-time/</guid><description>This table was concerned with epochs or periods of time commonly used to describe, classify and retrieve moving images, using terms such as &amp;ldquo;Victorian&amp;rdquo;, &amp;ldquo;post-war&amp;rdquo;, &amp;ldquo;pre-modern&amp;rdquo;, etc.</description></item><item><title>subjective time</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/subjective-time/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/subjective-time/</guid><description>Time not only as duration, but as perceived through subjective experience, by audiences and by characters on screen. [[public_notes/Sculpting Time with Computers/Belén Vidal|Belén]] pointed our attention to the relation between time as duration, e.</description></item><item><title>a list of all notes here</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/List-of-all-notes/</link><pubDate>Fri, 14 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/List-of-all-notes/</guid><description>Here is a list of all notes (excluding [[public_notes/Sculpting Time with Computers/Participants|participants]]) that together give an account of our activities at the [[public_notes/Sculpting Time with Computers/Sculpting Time With Computers|Sculpting Time With Computers]] workshop.</description></item><item><title>Annotation guidelines</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Annotation-guidelines/</link><pubDate>Fri, 14 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Annotation-guidelines/</guid><description>During day two, [[public_notes/Sculpting Time with Computers/Mila Oiva|Mila]] and [[public_notes/Sculpting Time with Computers/Andrea Farina|Andrea]] worked on a series of guidelines for human annotation of the the soviet news reels, focusing on scenes or &amp;ldquo;blocs&amp;rdquo;, rather than stories.</description></item><item><title>Participants</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Participants/</link><pubDate>Fri, 14 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Participants/</guid><description>Participants of the [[public_notes/Sculpting Time with Computers/Sculpting Time With Computers|Sculpting Time With Computers]] workshop at KCL, 6-7 July, 2023.</description></item><item><title>ideas and next steps</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/ideas-and-next-steps/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/ideas-and-next-steps/</guid><description>Three main ideas were discussed to follow up on the work from this workshop, in order of scale:
Submit a joint abstract to the CUDAN Open Lab conference in Tallinn, in December.</description></item><item><title>panel on high-dimensional cinema</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/High-dimensional-cinema/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/High-dimensional-cinema/</guid><description>As a public-facing part of the [[public_notes/Sculpting Time with Computers/Sculpting Time With Computers|Sculpting Time With Computers workshop]], in this “meeting of the labs” event, [[public_notes/Sculpting Time with Computers/Nanne van Noord|Nanne van Noord]], [[public_notes/Sculpting Time with Computers/Mila Oiva|Mila Oiva]] and myself got together to to present recent research and engage in conversation about recent advances at the intersection between cultural analytics, computational aesthetics, and machine learning.</description></item><item><title>Reverse compression as motion estimation</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Reverse-compression-as-motion-estimation/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Reverse-compression-as-motion-estimation/</guid><description>I wrote this for my PhD. I haven&amp;rsquo;t found the actual experiment files, but the method can be recreated from the formulas if there&amp;rsquo;s any interest in that.</description></item><item><title>Andrea Farina</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Andrea-Farina/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Andrea-Farina/</guid><description>About Andrea Farina is a PhD Researcher in Digital Humanities. So far, he has been involved in the syntactic or semantic annotation for the following on-going projects: the Greek WordNet, the Latin WordNet, the Sanskrit WordNet, and the Digital Corpus of Sanskrit.</description></item><item><title>Belén Vidal</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Bel%C3%A9n-Vidal/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Bel%C3%A9n-Vidal/</guid><description>About Belén Vidal is Reader in Film Studies. She is the author of Figuring the Past: Period Film and the Mannerist Aesthetic (Amsterdam University Press, 2012) and Heritage Film.</description></item><item><title>Carlo Bretti</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Carlo-Bretti/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Carlo-Bretti/</guid><description>About I’m a first-year PhD candidate at the Multimedia Analytics Lab of the University of Amsterdam under the supervision of Nanne van Noord and Pascal Mettes.</description></item><item><title>collections</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/collections/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/collections/</guid><description>In this cluster are [[public_notes/Sculpting Time with Computers/Jake Berger|Jake Berger]] and [[public_notes/Sculpting Time with Computers/Stephen McConnachie|Stephen McConnachie]], who brought to the group their experience and knowledge working with archives and large collections of moving images, from an institutional perspective in the UK.</description></item><item><title>computational</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/computational/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/computational/</guid><description>In the computational cluster we had [[public_notes/Sculpting Time with Computers/Nanne van Noord|Nanne van Noord]], [[public_notes/Sculpting Time with Computers/Carlo Bretti|Carlo Bretti]], and [[public_notes/Sculpting Time with Computers/Andrea Farina|Andrea Farina]].</description></item><item><title>day one</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/day-one/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/day-one/</guid><description>6 July Introduction session After informal conversations during coffee, we got started with a general introduction, where I gave an overview of the workshop, including its format, aims and, a provisional definition of cinematic time.</description></item><item><title>design</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/design/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/design/</guid><description>The design cluster included [[public_notes/Sculpting Time with Computers/Pauline van Mourik Broekman|Pauline van Mourik Broekman]], [[public_notes/Sculpting Time with Computers/Joel McKim|Joel McKim]], and myself.</description></item><item><title>film</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/film/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/film/</guid><description>In the film cluster we had [[public_notes/Sculpting Time with Computers/Belén Vidal|Belén Vidal]], [[public_notes/Sculpting Time with Computers/Tom Brown|Tom Brown]], and [[public_notes/Sculpting Time with Computers/Isadora Campregher|Isadora Campregher]].</description></item><item><title>high-level reasoning about time</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/high-level-reasoning-about-time/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/high-level-reasoning-about-time/</guid><description>The [[public_notes/Sculpting Time with Computers/film|film]] cluster contributed by outlining the diversity of approaches and levels of analysis about time in moving images.</description></item><item><title>Isadora Campregher</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Isadora-Campregher/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Isadora-Campregher/</guid><description>About Research Associate and Lecturer at Goethe University. Research associate @DiciHub. Producer @Authoredby_AI. Amateur data scientist.
Background International Relations and MA in Sociology with a focus on Gender Studies from Universidade Federal do Rio Grande do Sul (UFRGS) in Porto Alegre, Brazil.</description></item><item><title>Jake Berger</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Jake-Berger/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Jake-Berger/</guid><description>About Jake is Executive Product Manager of BBC Archive.
Background I&amp;rsquo;m not sure! Jake, if you are reading this and want to add something here, give me a shout.</description></item><item><title>Joel McKim</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Joel-McKim/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Joel-McKim/</guid><description>About Joel&amp;rsquo;s work focuses on the study of digital images and the impact of digital technologies on architecture, art and design.</description></item><item><title>long list of ideas</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/long-list-of-ideas/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/long-list-of-ideas/</guid><description>We split into three working groups mixing from our initial disciplinary clusters. The goal was to come up with as many ideas as possible for a system/tool/method that we thought would be valuable for investigating cinematic time.</description></item><item><title>Mila Oiva</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Mila-Oiva/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Mila-Oiva/</guid><description>About Mila Oiva is a cultural historian enthusiastic about identifying patterns of transnational circulation of knowledge and ideas in a long temporal perspective.</description></item><item><title>Nanne van Noord</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Nanne-van-Noord/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Nanne-van-Noord/</guid><description>About Assistant Professor in the Multimedia Analytics lab of the University of Amsterdam. I’m interested in improving Multimedia Analysis with and for Visual Culture.</description></item><item><title>Pauline van Mourik Broekman</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Pauline-van-Mourik-Broekman/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Pauline-van-Mourik-Broekman/</guid><description>About Artist and lecturer at the UAL&amp;rsquo;s Creative Computing Institute. Co-founder of Mute magazinethat covered cyberculture, artistic practice, left-wing politics, urban regeneration, biopolitics, direct democracy, net art, the commons, horizontality and UK arts.</description></item><item><title>Stephen McConnachie</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Stephen-McConnachie/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Stephen-McConnachie/</guid><description>About Stephen has worked at the BFI since 2009. In his current role he leads the Data and Digital Preservation department, with strategic and operational responsibility for the BFI National Archive’s data and digital preservation policies, standards, practices and infrastructure.</description></item><item><title>Tom Brown</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Tom-Brown/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Tom-Brown/</guid><description>About Tom Brown is Senior Lecturer in Film Studies. He is the author of two monographs: Spectacle in “Classical” Cinemas: Musicality and Historicity in the 1930s (2016) and Breaking the Fourth Wall: Direct Address in the Cinema (2012).</description></item><item><title>Video-understanding community</title><link>https://garden.movingpixel.net/public_notes/Video-understanding-community/</link><pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Video-understanding-community/</guid><description>Some interesting recent work on video understanding tasks and practitioners from computer science.
CMD Challenge From the VGG group at Oxford.</description></item><item><title>5 principles of life</title><link>https://garden.movingpixel.net/public_notes/5-principles-of-life/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/5-principles-of-life/</guid><description>Some very high-level background about cell-biology for my talk on [[public_notes/Cultural Metabolism and LLMs on wheels|Cultural Metabolism and LLMs on wheels]] at Prague earlier this year.</description></item><item><title>Video as data in the US</title><link>https://garden.movingpixel.net/public_notes/Video-as-data/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Video-as-data/</guid><description>This looks interesting! See twitter post here.
![[assets/images/Pasted image 20230523190034.png]]</description></item><item><title>Videogrep</title><link>https://garden.movingpixel.net/public_notes/Tools/Videogrep/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Videogrep/</guid><description>Videogrep is a command line tool that searches through dialog in video files and makes supercuts based on what it finds.</description></item><item><title>Zeeschuimer</title><link>https://garden.movingpixel.net/public_notes/Tools/Zeeschuimer/</link><pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Zeeschuimer/</guid><description>Zeeschuimer is a browser extension that monitors internet traffic while you are browsing a social media site, and collects data about the items you see in a platform&amp;rsquo;s web interface for later systematic analysis.</description></item><item><title>small large LLMs</title><link>https://garden.movingpixel.net/public_notes/small-large-LLMs/</link><pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/small-large-LLMs/</guid><description>My colleague Mercedes Bunz made me aware of this allegedly leaked document from a Google engineer, in which they make the case for open-sourcing their models.</description></item><item><title>Streaming Video Model</title><link>https://garden.movingpixel.net/public_notes/Tools/Streaming-Video-Model/</link><pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Streaming-Video-Model/</guid><description>Interesting video model that accounts for frames and sequences in a unified model. Abstract:
Video understanding tasks have traditionally been modeled by two separate architectures, specially tailored for two distinct tasks.</description></item><item><title>Creative AI Theory and Practice</title><link>https://garden.movingpixel.net/public_notes/Creative-AI-Theory-and-Practice/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Creative-AI-Theory-and-Practice/</guid><description>The recording of our symposium on Creative AI is now available. Presentations are indexed at different timestamps.
On Friday 27 January 2023, Creative AI Lab at King’s College London/Serpentine (Professor Mercedes Bunz and curator Eva Jäger as Lab’s co-founders, Dr Daniel Chávez Heras, PhD student Alasdair Milne, Professor Joanna Zylinska) hosted a one-day symposium supported by the King’s Institute for Artificial Intelligence.</description></item><item><title>Creanalytics</title><link>https://garden.movingpixel.net/public_notes/Creanalytics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Creanalytics/</guid><description>Creanalytics: a portmanteau of creative and analytic.
This idea came up when writing about the[[private/To do/Towards a Computational Video Essay | computational video essay]], largely in response to creative and analytic research methods coexisting under a unified computational framework.</description></item><item><title>Human-centered machine vision?</title><link>https://garden.movingpixel.net/public_notes/Human-centered-machine-vision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Human-centered-machine-vision/</guid><description>From the Click and Collect: Show Me Your Dataset event at Somerset House. I was invited as part of a panel with Charlotte Webb and Kristina Pulejkova to discuss human-centred design in relation to AI.</description></item><item><title>Mermaid diagrams</title><link>https://garden.movingpixel.net/public_notes/Tools/Mermaid-diagrams/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Mermaid-diagrams/</guid><description>JavaScript based diagramming and charting tool that renders Markdown-inspired text definitions to create and modify diagrams dynamically.
It has a live editor for non-programmers, and has some tutorials.</description></item><item><title>Motion Canvas</title><link>https://garden.movingpixel.net/public_notes/Tools/Motion-Canvas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Tools/Motion-Canvas/</guid><description>Visualize Complex Ideas Programmatically. It&amp;rsquo;s a specialized tool designed to create informative vector animations and synchronize them with voice-overs.</description></item><item><title>NYU - Prague</title><link>https://garden.movingpixel.net/public_notes/Cultural-Metabolism-and-LLMs-on-wheels/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Cultural-Metabolism-and-LLMs-on-wheels/</guid><description>I was invited by the great people of the Digital Theory Lab at NYU to present this in Prague this summer.</description></item><item><title>Scultping Time with Computers</title><link>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Sculpting-Time-With-Computers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Sculpting-Time-with-Computers/Sculpting-Time-With-Computers/</guid><description>Interdisciplinary Approaches to Computational Moving Images This workshop brought together a group of researchers in the fields of digital and computational humanities, computer vision, film, digital preservation and archives, cultural history, and creative computing, to explore together emerging computational approaches to the study of time in moving images.</description></item><item><title>The Digital Pastoral</title><link>https://garden.movingpixel.net/public_notes/The-Digital-Pastoral/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/The-Digital-Pastoral/</guid><description>I created the image below using #stablediffusion (before it was cool and every media scholar started doing it) and used it for my very short presentation at [[Transmediale 2023 | Transmediale 2023]].</description></item><item><title>Transmediale 2023</title><link>https://garden.movingpixel.net/public_notes/Transmediale-2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.movingpixel.net/public_notes/Transmediale-2023/</guid><description>I attended Transmediale and gave a very small presentation as part of the panel Toward Minor Tech.</description></item></channel></rss>